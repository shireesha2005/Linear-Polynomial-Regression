# Linear-Polynomial-Regression
Linear and Polynomial Regression with Bias-Variance Tradeoff

The Mean Squared Error (MSE) is used as the loss function:
            1/n sumation of(y - y^)^2
            n= number of inputs
            y = actual value
            y cap(y^) = predicted value 
* Why squared error is used for Penalizes large errors and Prevents error cancellation
* What minimizing loss means
  Loss represents how far off the model's predictions are from actual targets and minimizing the loss function can be done by the  training process of reducing the error between predicted and actual values by optimizing model parameters.
*How the model parameters influence the loss
  Model parameters  directly effect a model's output, and each every parameter has it's own influence on model peformance and output therefore its prediction error or loss, acting as the primary lever for optimization.
*Why does training error always decrease with higher polynomial degree?
 
  
